{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79fdd771-aada-4898-901e-b733c833134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#from common.arguments import parse_args\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import sys\n",
    "import errno\n",
    "\n",
    "from common.camera import *\n",
    "from common.model import *\n",
    "from common.loss import *\n",
    "from common.generators import ChunkedGenerator, UnchunkedGenerator\n",
    "from time import time\n",
    "from common.utils import deterministic_random\n",
    "\n",
    "from common.h36m_dataset import Human36mDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05fe11b-e8a3-44e4-ae1f-fd7041ff2478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h36m\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    dataset = 'h36m'\n",
    "    keypoints = 'gt'\n",
    "    subjects_train = ['S1','S5','S6','S7','S8']\n",
    "    subjects_test = ['S9','S11']\n",
    "    subjects_unlabeled = ''\n",
    "    actions = '*'\n",
    "    checkpoint = 'checkpoint243'\n",
    "    checkpoint_frequency = 10\n",
    "    render = False\n",
    "    data_augmentation = True\n",
    "    \n",
    "    #Model\n",
    "    stride = 1\n",
    "    epochs = 80\n",
    "    batch_size = 1024\n",
    "    dropout = 0.25\n",
    "    learning_rate = 0.001\n",
    "    lr_decay = 0.95\n",
    "    architecture = '3,3,3,3,3'\n",
    "    causal = True\n",
    "    channels = 1024\n",
    "    resume = False\n",
    "    evaluate = ''\n",
    "    \n",
    "    #Experimental\n",
    "    subset = 1\n",
    "    downsample = 1\n",
    "    warmup = 1\n",
    "    disable_optimizations = False\n",
    "    dense = False\n",
    "    no_eval = False\n",
    "    \n",
    "args = Args()\n",
    "print(args.dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "255a56b8-d610-43f7-bc7d-c6930146c592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data_3d_h36m.npz\n"
     ]
    }
   ],
   "source": [
    "dataset_path = dataset_path = 'data/data_3d_' + args.dataset + '.npz'\n",
    "print(dataset_path)\n",
    "dataset = Human36mDataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26fd6c69-dfc4-449a-8108-90f9e333f615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing 3d data...\n"
     ]
    }
   ],
   "source": [
    "print('Preparing 3d data...')\n",
    "for subject in dataset.subjects():\n",
    "    for action in dataset[subject].keys():\n",
    "        anim = dataset[subject][action]\n",
    "        \n",
    "        if 'positions' in anim:\n",
    "            positions_3d = []\n",
    "            for cam in anim['cameras']:\n",
    "                pos_3d = world_to_camera(anim['positions'], R=cam['orientation'], t=cam['translation'])\n",
    "                pos_3d[:, 1:] -= pos_3d[:, :1] # Remove global offset, but keep trajectory in first position\n",
    "                positions_3d.append(pos_3d)\n",
    "            anim['positions_3d'] = positions_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748a384f-4621-4de3-8e4a-7265c100efeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2D detections...\n"
     ]
    }
   ],
   "source": [
    "print('Loading 2D detections...')\n",
    "keypoints = np.load('data/data_2d_' + args.dataset + '_' + args.keypoints + '.npz', allow_pickle=True)\n",
    "keypoints_metadata = keypoints['metadata'].item()\n",
    "keypoints_symmetry = keypoints_metadata['keypoints_symmetry']\n",
    "kps_left, kps_right = list(keypoints_symmetry[0]), list(keypoints_symmetry[1])\n",
    "joints_left, joints_right = list(dataset.skeleton().joints_left()), list(dataset.skeleton().joints_right())\n",
    "keypoints = keypoints['positions_2d'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c255ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in dataset.subjects():\n",
    "    assert subject in keypoints, 'Subject {} is missing from the 2D detections dataset'.format(subject)\n",
    "    for action in dataset[subject].keys():\n",
    "        assert action in keypoints[subject], 'Action {} of subject {} is missing from the 2D detections dataset'.format(action, subject)\n",
    "        if 'positions_3d' not in dataset[subject][action]:\n",
    "            continue\n",
    "            \n",
    "        for cam_idx in range(len(keypoints[subject][action])):\n",
    "            \n",
    "            # We check for >= instead of == because some videos in H3.6M contain extra frames\n",
    "            mocap_length = dataset[subject][action]['positions_3d'][cam_idx].shape[0]\n",
    "            assert keypoints[subject][action][cam_idx].shape[0] >= mocap_length\n",
    "            \n",
    "            if keypoints[subject][action][cam_idx].shape[0] > mocap_length:\n",
    "                # Shorten sequence\n",
    "                keypoints[subject][action][cam_idx] = keypoints[subject][action][cam_idx][:mocap_length]\n",
    "\n",
    "        assert len(keypoints[subject][action]) == len(dataset[subject][action]['positions_3d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d14194",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in keypoints.keys():\n",
    "    for action in keypoints[subject]:\n",
    "        for cam_idx, kps in enumerate(keypoints[subject][action]):\n",
    "            # Normalize camera frame\n",
    "            cam = dataset.cameras()[subject][cam_idx]\n",
    "            kps[..., :2] = normalize_screen_coordinates(kps[..., :2], w=cam['res_w'], h=cam['res_h'])\n",
    "            keypoints[subject][action][cam_idx] = kps\n",
    "subjects_train = args.subjects_train\n",
    "subjects_semi = [] if not args.subjects_unlabeled else args.subjects_unlabeled.split(',')\n",
    "if not args.render:\n",
    "    subjects_test = args.subjects_test\n",
    "else:\n",
    "    subjects_test = [args.viz_subject]\n",
    "\n",
    "semi_supervised = len(subjects_semi) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9cf8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(subjects, action_filter=None, subset=1, parse_3d_poses=True):\n",
    "    out_poses_3d = []\n",
    "    out_poses_2d = []\n",
    "    out_camera_params = []\n",
    "    for subject in subjects:\n",
    "        for action in keypoints[subject].keys():\n",
    "            ############################\n",
    "            if action_filter is not None:\n",
    "                found = False\n",
    "                for a in action_filter:\n",
    "                    if action.startswith(a):\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    continue\n",
    "            ############################    \n",
    "            poses_2d = keypoints[subject][action]\n",
    "            for i in range(len(poses_2d)): # Iterate across cameras\n",
    "                out_poses_2d.append(poses_2d[i])\n",
    "            # 카메라 4방향 이어주기\n",
    "            \n",
    "            if subject in dataset.cameras():\n",
    "                cams = dataset.cameras()[subject]\n",
    "                assert len(cams) == len(poses_2d), 'Camera count mismatch'\n",
    "                for cam in cams:\n",
    "                    if 'intrinsic' in cam:\n",
    "                        out_camera_params.append(cam['intrinsic'])\n",
    "            # 카메라 내부 파라미터\n",
    "            \n",
    "            if parse_3d_poses and 'positions_3d' in dataset[subject][action]:\n",
    "                poses_3d = dataset[subject][action]['positions_3d']\n",
    "                assert len(poses_3d) == len(poses_2d), 'Camera count mismatch'\n",
    "                for i in range(len(poses_3d)): # Iterate across cameras\n",
    "                    out_poses_3d.append(poses_3d[i])\n",
    "    \n",
    "    if len(out_camera_params) == 0:\n",
    "        out_camera_params = None\n",
    "    if len(out_poses_3d) == 0:\n",
    "        out_poses_3d = None\n",
    "    \n",
    "    stride = args.downsample\n",
    "    if subset < 1:\n",
    "        for i in range(len(out_poses_2d)):\n",
    "            n_frames = int(round(len(out_poses_2d[i])//stride * subset)*stride)\n",
    "            start = deterministic_random(0, len(out_poses_2d[i]) - n_frames + 1, str(len(out_poses_2d[i])))\n",
    "            out_poses_2d[i] = out_poses_2d[i][start:start+n_frames:stride]\n",
    "            if out_poses_3d is not None:\n",
    "                out_poses_3d[i] = out_poses_3d[i][start:start+n_frames:stride]\n",
    "    elif stride > 1:\n",
    "        # Downsample as requested\n",
    "        for i in range(len(out_poses_2d)):\n",
    "            out_poses_2d[i] = out_poses_2d[i][::stride]\n",
    "            if out_poses_3d is not None:\n",
    "                out_poses_3d[i] = out_poses_3d[i][::stride]\n",
    "    \n",
    "\n",
    "    return out_camera_params, out_poses_3d, out_poses_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d03f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_filter = None if args.actions == '*' else args.actions.split(',')\n",
    "if action_filter is not None:\n",
    "    print('Selected actions:', action_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a136e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras_valid, poses_valid, poses_valid_2d = fetch(subjects_test, action_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a3d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_widths = [int(x) for x in args.architecture.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "953c7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 생성\n",
    "if not args.disable_optimizations and not args.dense and args.stride == 1:\n",
    "    # Use optimized model for single-frame predictions\n",
    "    model_pos_train = TemporalModelOptimized1f(poses_valid_2d[0].shape[-2], poses_valid_2d[0].shape[-1], dataset.skeleton().num_joints(),\n",
    "                                filter_widths=filter_widths, causal=args.causal, dropout=args.dropout, channels=args.channels)\n",
    "else:\n",
    "    # When incompatible settings are detected (stride > 1, dense filters, or disabled optimization) fall back to normal model\n",
    "    model_pos_train = TemporalModel(poses_valid_2d[0].shape[-2], poses_valid_2d[0].shape[-1], dataset.skeleton().num_joints(),\n",
    "                                filter_widths=filter_widths, causal=args.causal, dropout=args.dropout, channels=args.channels,\n",
    "                                dense=args.dense)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6302dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Receptive field: 243 frames\n"
     ]
    }
   ],
   "source": [
    "model_pos = TemporalModel(poses_valid_2d[0].shape[-2], poses_valid_2d[0].shape[-1], dataset.skeleton().num_joints(),\n",
    "                            filter_widths=filter_widths, causal=args.causal, dropout=args.dropout, channels=args.channels,\n",
    "                            dense=args.dense)\n",
    "model_pos.cuda()\n",
    "receptive_field = model_pos.receptive_field()\n",
    "print('INFO: Receptive field: {} frames'.format(receptive_field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a42afbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using causal convolutions\n"
     ]
    }
   ],
   "source": [
    "pad = (receptive_field - 1) // 2 # Padding on each side\n",
    "if args.causal:\n",
    "    print('INFO: Using causal convolutions')\n",
    "    causal_shift = pad\n",
    "else:\n",
    "    causal_shift = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ccc43ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1            [-1, 1024, 241]         104,448\n",
      "       BatchNorm1d-2            [-1, 1024, 241]           2,048\n",
      "              ReLU-3            [-1, 1024, 241]               0\n",
      "           Dropout-4            [-1, 1024, 241]               0\n",
      "            Conv1d-5            [-1, 1024, 235]       3,145,728\n",
      "       BatchNorm1d-6            [-1, 1024, 235]           2,048\n",
      "              ReLU-7            [-1, 1024, 235]               0\n",
      "           Dropout-8            [-1, 1024, 235]               0\n",
      "            Conv1d-9            [-1, 1024, 235]       1,048,576\n",
      "      BatchNorm1d-10            [-1, 1024, 235]           2,048\n",
      "             ReLU-11            [-1, 1024, 235]               0\n",
      "          Dropout-12            [-1, 1024, 235]               0\n",
      "           Conv1d-13            [-1, 1024, 217]       3,145,728\n",
      "      BatchNorm1d-14            [-1, 1024, 217]           2,048\n",
      "             ReLU-15            [-1, 1024, 217]               0\n",
      "          Dropout-16            [-1, 1024, 217]               0\n",
      "           Conv1d-17            [-1, 1024, 217]       1,048,576\n",
      "      BatchNorm1d-18            [-1, 1024, 217]           2,048\n",
      "             ReLU-19            [-1, 1024, 217]               0\n",
      "          Dropout-20            [-1, 1024, 217]               0\n",
      "           Conv1d-21            [-1, 1024, 163]       3,145,728\n",
      "      BatchNorm1d-22            [-1, 1024, 163]           2,048\n",
      "             ReLU-23            [-1, 1024, 163]               0\n",
      "          Dropout-24            [-1, 1024, 163]               0\n",
      "           Conv1d-25            [-1, 1024, 163]       1,048,576\n",
      "      BatchNorm1d-26            [-1, 1024, 163]           2,048\n",
      "             ReLU-27            [-1, 1024, 163]               0\n",
      "          Dropout-28            [-1, 1024, 163]               0\n",
      "           Conv1d-29              [-1, 1024, 1]       3,145,728\n",
      "      BatchNorm1d-30              [-1, 1024, 1]           2,048\n",
      "             ReLU-31              [-1, 1024, 1]               0\n",
      "          Dropout-32              [-1, 1024, 1]               0\n",
      "           Conv1d-33              [-1, 1024, 1]       1,048,576\n",
      "      BatchNorm1d-34              [-1, 1024, 1]           2,048\n",
      "             ReLU-35              [-1, 1024, 1]               0\n",
      "          Dropout-36              [-1, 1024, 1]               0\n",
      "           Conv1d-37                [-1, 51, 1]          52,275\n",
      "================================================================\n",
      "Total params: 16,952,371\n",
      "Trainable params: 16,952,371\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 46.03\n",
      "Params size (MB): 64.67\n",
      "Estimated Total Size (MB): 110.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "torchsummary.summary(model_pos,input_size = (243,17,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0a5be83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Trainable parameter count: 16952371\n"
     ]
    }
   ],
   "source": [
    "model_params = 0\n",
    "for parameter in model_pos.parameters():\n",
    "    model_params += parameter.numel()\n",
    "print('INFO: Trainable parameter count:', model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d6544a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model_pos = model_pos.cuda()\n",
    "    model_pos_train = model_pos_train.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a67a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.resume or args.evaluate:\n",
    "#     chk_filename = os.path.join(args.checkpoint, args.resume if args.resume else args.evaluate)\n",
    "#     print('Loading checkpoint', chk_filename)\n",
    "#     checkpoint = torch.load(chk_filename, map_location=lambda storage, loc: storage)\n",
    "#     print('This model was trained for {} epochs'.format(checkpoint['epoch']))\n",
    "#     model_pos_train.load_state_dict(checkpoint['model_pos'])\n",
    "#     model_pos.load_state_dict(checkpoint['model_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cadde0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on 543344 frames\n"
     ]
    }
   ],
   "source": [
    "test_generator = UnchunkedGenerator(cameras_valid, poses_valid, poses_valid_2d,\n",
    "                                    pad=pad, causal_shift=causal_shift, augment=False,\n",
    "                                    kps_left=kps_left, kps_right=kps_right, joints_left=joints_left, joints_right=joints_right)\n",
    "print('INFO: Testing on {} frames'.format(test_generator.num_frames()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ba378f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Training on 1559752 frames\n"
     ]
    }
   ],
   "source": [
    "#Train 일 경우\n",
    "\n",
    "cameras_train, poses_train, poses_train_2d = fetch(subjects_train, action_filter, subset=args.subset)\n",
    "\n",
    "lr = args.learning_rate\n",
    "\n",
    "optimizer = optim.Adam(model_pos_train.parameters(), lr=lr, amsgrad=True)\n",
    "\n",
    "lr_decay = args.lr_decay\n",
    "\n",
    "losses_3d_train = []\n",
    "losses_3d_train_eval = []\n",
    "losses_3d_valid = []\n",
    "\n",
    "epoch = 0\n",
    "initial_momentum = 0.1\n",
    "final_momentum = 0.001\n",
    "\n",
    "\n",
    "train_generator = ChunkedGenerator(args.batch_size//args.stride, cameras_train, poses_train, poses_train_2d, args.stride,\n",
    "                                   pad=pad, causal_shift=causal_shift, shuffle=True, augment=args.data_augmentation,\n",
    "                                   kps_left=kps_left, kps_right=kps_right, joints_left=joints_left, joints_right=joints_right)\n",
    "train_generator_eval = UnchunkedGenerator(cameras_train, poses_train, poses_train_2d,\n",
    "                                          pad=pad, causal_shift=causal_shift, augment=False)\n",
    "print('INFO: Training on {} frames'.format(train_generator_eval.num_frames()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b92fcc77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73522e55565c4fdc92df97600b805bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] time 5.33 lr 0.001000 3d_train 116.890960 3d_eval 355.191790 3d_valid 337.576410\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d14058ec42b443b8e9f622aab7ccf25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] time 5.34 lr 0.000950 3d_train 50.087647 3d_eval 33.756590 3d_valid 45.796654\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a139ea0662452b84ecadfa2bf0c428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] time 5.36 lr 0.000902 3d_train 39.621540 3d_eval 27.870326 3d_valid 43.891596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e2b0a3f438422fbe4df22a6a96d2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] time 5.36 lr 0.000857 3d_train 35.218264 3d_eval 24.933068 3d_valid 41.749663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc80248230c44d12b59b72496a19091e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] time 5.35 lr 0.000815 3d_train 32.677296 3d_eval 21.873658 3d_valid 40.598365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106549deb6a14c7cbf8fcb31b4968db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] time 5.35 lr 0.000774 3d_train 30.973289 3d_eval 20.972903 3d_valid 41.063472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88dfd7c1b2774106ba1b24d094e70853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] time 5.33 lr 0.000735 3d_train 29.544377 3d_eval 20.902796 3d_valid 39.909230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e38f3e6f074566990bd3a6603ba1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] time 5.42 lr 0.000698 3d_train 28.502274 3d_eval 20.422116 3d_valid 40.493350\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36755fa880ee4f3f8f985da441459104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] time 5.38 lr 0.000663 3d_train 27.637595 3d_eval 19.873062 3d_valid 40.219244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a6c5e0a9c246dc8798cd6f3fc798c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] time 5.37 lr 0.000630 3d_train 26.923166 3d_eval 18.379285 3d_valid 40.168619\n",
      "Saving checkpoint to checkpoint243/epoch_10.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab33e3fdbe04821bedbecd53196ee52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11] time 5.38 lr 0.000599 3d_train 26.337419 3d_eval 16.829786 3d_valid 41.033299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a413bc4556f482b8a0c8056216184d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12] time 5.37 lr 0.000569 3d_train 25.838789 3d_eval 16.603109 3d_valid 40.920560\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0120b8e193403d927886e271532429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13] time 5.37 lr 0.000540 3d_train 25.361602 3d_eval 16.203176 3d_valid 40.471323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f7c05dcf7a4278b839fea15e089881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14] time 5.37 lr 0.000513 3d_train 24.984937 3d_eval 15.897033 3d_valid 38.831563\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b837b2d367df4c3780d7e325eb439e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15] time 5.40 lr 0.000488 3d_train 24.637322 3d_eval 15.702632 3d_valid 39.562539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ec29bcd40a408ebb9730d3d15acb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16] time 5.35 lr 0.000463 3d_train 24.289378 3d_eval 14.946837 3d_valid 39.089323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4949a73f0441b39b0a9c8c181f17d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17] time 5.36 lr 0.000440 3d_train 24.005707 3d_eval 14.765918 3d_valid 39.064628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2619982cf04e51855266e41cc4dcb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18] time 5.36 lr 0.000418 3d_train 23.743726 3d_eval 14.632770 3d_valid 38.254508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654c171cdaa94dc8a6418c653ab1d0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19] time 5.36 lr 0.000397 3d_train 23.518460 3d_eval 14.511460 3d_valid 38.564502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c20b77789154e42a3cb9a9891bd40ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20] time 5.37 lr 0.000377 3d_train 23.287615 3d_eval 14.670372 3d_valid 39.904604\n",
      "Saving checkpoint to checkpoint243/epoch_20.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc574ef527a4905bbe200f22aeb44f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21] time 5.28 lr 0.000358 3d_train 23.138689 3d_eval 14.120953 3d_valid 38.629822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b1b45709b94f708929310330bfb980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22] time 5.21 lr 0.000341 3d_train 22.920165 3d_eval 13.671640 3d_valid 38.131200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fe5d269df648eaa711d502875f15c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23] time 5.21 lr 0.000324 3d_train 22.761301 3d_eval 13.874411 3d_valid 38.702158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eaaa4522d1d48019763dc2a89577584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24] time 5.21 lr 0.000307 3d_train 22.598818 3d_eval 13.508005 3d_valid 38.757681\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6486ed061645d39fed3fc71289766c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25] time 5.21 lr 0.000292 3d_train 22.445936 3d_eval 13.809196 3d_valid 38.888877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533829da980044e58bd5347b8ab53ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26] time 5.21 lr 0.000277 3d_train 22.309744 3d_eval 13.631745 3d_valid 39.026564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83893905f824c008ef64ea8e5aeddf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] time 5.21 lr 0.000264 3d_train 22.181499 3d_eval 13.106290 3d_valid 38.725325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6416bbc72cab41dfaf96361a93ca8ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28] time 5.21 lr 0.000250 3d_train 22.041159 3d_eval 13.289114 3d_valid 38.272492\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c588e4461b949d7a4617d387d743bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29] time 5.21 lr 0.000238 3d_train 21.950886 3d_eval 13.305452 3d_valid 38.613943\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3a230f7d9f4cf1b0d053c098b646c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30] time 5.21 lr 0.000226 3d_train 21.856167 3d_eval 12.961989 3d_valid 38.703318\n",
      "Saving checkpoint to checkpoint243/epoch_30.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4eb69daa1054bb79790313370f2b354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31] time 5.21 lr 0.000215 3d_train 21.743349 3d_eval 12.861254 3d_valid 38.828291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20ce87ca2b14907a4388c4807751e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32] time 5.21 lr 0.000204 3d_train 21.650394 3d_eval 13.683862 3d_valid 39.981729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fcae27a7f049e2a4ca08da11e9a04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33] time 5.21 lr 0.000194 3d_train 21.598281 3d_eval 12.467966 3d_valid 38.944511\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef4feeb16f04a9dbf6b1742649d42fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34] time 5.21 lr 0.000184 3d_train 21.475128 3d_eval 12.600511 3d_valid 38.748769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc18384cfc8d45f58cac5af36253d5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35] time 5.21 lr 0.000175 3d_train 21.411590 3d_eval 12.603541 3d_valid 39.492674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6840f698087b4f0e954042db7662a468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36] time 5.21 lr 0.000166 3d_train 21.325329 3d_eval 12.644999 3d_valid 39.355841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c38bb9805214066bf819febd163b92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37] time 5.21 lr 0.000158 3d_train 21.254103 3d_eval 12.128708 3d_valid 39.050177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201693ccbf58455fb113e7e064e49faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38] time 5.21 lr 0.000150 3d_train 21.206333 3d_eval 12.452605 3d_valid 38.842064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5805db6c0da944b69cd61eb58721fbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39] time 5.21 lr 0.000142 3d_train 21.133921 3d_eval 12.542133 3d_valid 39.021029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24231e82845407db9942a66dde350e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] time 5.21 lr 0.000135 3d_train 21.078054 3d_eval 12.055871 3d_valid 38.923244\n",
      "Saving checkpoint to checkpoint243/epoch_40.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee94d93a77eb4521ae0ffe86d63733f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41] time 5.21 lr 0.000129 3d_train 21.020990 3d_eval 12.022316 3d_valid 38.674885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c59323e6e7e49f286412995e4e59d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42] time 5.21 lr 0.000122 3d_train 20.962173 3d_eval 12.227107 3d_valid 39.297169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c23bf2598c4d0b9e0eb1dcd559d7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43] time 5.21 lr 0.000116 3d_train 20.899207 3d_eval 12.257128 3d_valid 39.874805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bb09f5861641ce826939927f037cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44] time 5.21 lr 0.000110 3d_train 20.869627 3d_eval 11.819356 3d_valid 38.402316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc8d1910e31465d9ceeb21fd792b946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45] time 5.21 lr 0.000105 3d_train 20.824658 3d_eval 11.845611 3d_valid 38.260401\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9683d1c2be445889d6bfeca6ebfe33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46] time 5.21 lr 0.000099 3d_train 20.780243 3d_eval 11.799086 3d_valid 38.457384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6701bf4aae364139988f88a0a0df46f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47] time 5.21 lr 0.000094 3d_train 20.732103 3d_eval 11.756694 3d_valid 38.620203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442dd5055504475895e4432edcf38eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48] time 5.21 lr 0.000090 3d_train 20.693376 3d_eval 11.829856 3d_valid 38.899253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c09c74b7204f6182a24066b065e56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49] time 5.21 lr 0.000085 3d_train 20.657083 3d_eval 11.794895 3d_valid 39.045839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eb007cb423468f9ab85724f1d7ac63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50] time 5.21 lr 0.000081 3d_train 20.630733 3d_eval 11.516406 3d_valid 38.703443\n",
      "Saving checkpoint to checkpoint243/epoch_50.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfa414ef80342d6bc260d14ec3b28ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51] time 5.21 lr 0.000077 3d_train 20.599391 3d_eval 11.596773 3d_valid 38.847996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1b2eb1c59f454499e99506a66b66a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52] time 5.21 lr 0.000073 3d_train 20.563764 3d_eval 11.600436 3d_valid 39.102986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5e3e299ca340479612d81af487cc13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53] time 5.21 lr 0.000069 3d_train 20.539040 3d_eval 11.503220 3d_valid 38.499212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f546dcb626334caf9578865df2eaa60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54] time 5.21 lr 0.000066 3d_train 20.506021 3d_eval 11.550083 3d_valid 38.752591\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b0766a6e724b129ea6aaafb25af454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55] time 5.21 lr 0.000063 3d_train 20.477454 3d_eval 11.549540 3d_valid 38.384964\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f882413cd34cb6aab57c9888b43ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56] time 5.21 lr 0.000060 3d_train 20.452519 3d_eval 11.563563 3d_valid 38.824467\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dc9a1dd0e24c87bda10884fb54691a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57] time 5.21 lr 0.000057 3d_train 20.425400 3d_eval 11.531846 3d_valid 38.541515\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53dc60066f14c168f4c5db9d55cedea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58] time 5.21 lr 0.000054 3d_train 20.399459 3d_eval 11.503964 3d_valid 38.636926\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2713e976280041b2a50b14a34978d9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59] time 5.21 lr 0.000051 3d_train 20.381361 3d_eval 11.263473 3d_valid 38.651220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f09233cf67466d88ddc099ec829766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60] time 5.21 lr 0.000048 3d_train 20.362182 3d_eval 11.310853 3d_valid 38.806888\n",
      "Saving checkpoint to checkpoint243/epoch_60.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230012ac084e49f5bf29ab7dbe3d78de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61] time 5.21 lr 0.000046 3d_train 20.344863 3d_eval 11.215829 3d_valid 38.456331\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f05327ce9644be488317e57d365325f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62] time 5.21 lr 0.000044 3d_train 20.320562 3d_eval 11.336555 3d_valid 38.884721\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ac0e47e23f476ab803b2a7ad69c34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63] time 5.21 lr 0.000042 3d_train 20.304228 3d_eval 11.284233 3d_valid 38.413521\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a0a4ec4f074677ad3b09d844e51e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64] time 5.21 lr 0.000039 3d_train 20.290248 3d_eval 11.295044 3d_valid 38.609171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1930f630b94d4275b4749604304b4373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65] time 5.21 lr 0.000038 3d_train 20.267818 3d_eval 11.124909 3d_valid 38.983074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac941a61dae48308a7d83b6e8afc142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66] time 5.21 lr 0.000036 3d_train 20.255464 3d_eval 11.318809 3d_valid 39.383180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7ee152de314b538234faad1fbbb691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67] time 5.21 lr 0.000034 3d_train 20.240259 3d_eval 11.228617 3d_valid 38.616482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e40620d5a6445d2bbf8854991c89915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68] time 5.21 lr 0.000032 3d_train 20.232035 3d_eval 11.264135 3d_valid 38.441254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983da63b2c7c418f93ead6eecc94ab41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69] time 5.21 lr 0.000031 3d_train 20.209382 3d_eval 11.302608 3d_valid 38.769610\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f33f8039c44ea089fe40eba70ffb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70] time 5.21 lr 0.000029 3d_train 20.201851 3d_eval 11.286225 3d_valid 38.574142\n",
      "Saving checkpoint to checkpoint243/epoch_70.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e670a63b19994e32b54e543d4cdec8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71] time 5.21 lr 0.000028 3d_train 20.190093 3d_eval 11.160279 3d_valid 38.566375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc6e8df030149b6a839e637358e9a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72] time 5.21 lr 0.000026 3d_train 20.177460 3d_eval 11.191695 3d_valid 38.807778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3565548ff1f4ac2a8667bd0c3ac25db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73] time 5.20 lr 0.000025 3d_train 20.161025 3d_eval 11.125308 3d_valid 38.732066\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb13ad727ff74d49bdbe5e2be9fecb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74] time 5.20 lr 0.000024 3d_train 20.150553 3d_eval 11.220531 3d_valid 38.751868\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a10f044ea1e444caab3ac16ea839989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75] time 5.20 lr 0.000022 3d_train 20.148501 3d_eval 11.271598 3d_valid 38.607541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c86c42d7dd48b4814885b4408605b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76] time 5.20 lr 0.000021 3d_train 20.137316 3d_eval 11.155431 3d_valid 38.451292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01eb724d5dc44c13a8cf31fdb9a5ad85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77] time 5.20 lr 0.000020 3d_train 20.128599 3d_eval 11.144589 3d_valid 38.638817\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4201ad46c14b358caeaf3f2ce434ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78] time 5.20 lr 0.000019 3d_train 20.123188 3d_eval 11.128915 3d_valid 38.574748\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9823c1e8ba244dacaae9494191cca35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79] time 5.20 lr 0.000018 3d_train 20.113758 3d_eval 11.063289 3d_valid 38.741394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e6b888960f47a5970aa8b9b7d1fb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80] time 5.20 lr 0.000017 3d_train 20.102735 3d_eval 11.175815 3d_valid 38.593270\n",
      "Saving checkpoint to checkpoint243/epoch_80.pth\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "while epoch < args.epochs:\n",
    "        start_time = time()\n",
    "        epoch_loss_3d_train = 0\n",
    "        N = 0\n",
    "        N_semi = 0\n",
    "        model_pos_train.train()\n",
    "        \n",
    "        for _, batch_3d, batch_2d in tqdm(train_generator.next_epoch()):\n",
    "                inputs_3d = torch.from_numpy(batch_3d.astype('float32'))\n",
    "                inputs_2d = torch.from_numpy(batch_2d.astype('float32'))\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs_3d = inputs_3d.cuda()\n",
    "                    inputs_2d = inputs_2d.cuda()\n",
    "                inputs_3d[:, :, 0] = 0\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Predict 3D poses\n",
    "                predicted_3d_pos = model_pos_train(inputs_2d)\n",
    "                loss_3d_pos = mpjpe(predicted_3d_pos, inputs_3d)\n",
    "                epoch_loss_3d_train += inputs_3d.shape[0]*inputs_3d.shape[1] * loss_3d_pos.item()\n",
    "                N += inputs_3d.shape[0]*inputs_3d.shape[1]\n",
    "\n",
    "                loss_total = loss_3d_pos\n",
    "                loss_total.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "        losses_3d_train.append(epoch_loss_3d_train / N)\n",
    "        \n",
    "        # End-of-epoch evaluation\n",
    "        with torch.no_grad():\n",
    "            model_pos.load_state_dict(model_pos_train.state_dict())\n",
    "            model_pos.eval()\n",
    "            \n",
    "            epoch_loss_3d_valid = 0\n",
    "            epoch_loss_2d_valid = 0\n",
    "            N = 0\n",
    "            \n",
    "            if not args.no_eval:\n",
    "                # Evaluate on test set\n",
    "                for cam, batch, batch_2d in test_generator.next_epoch():\n",
    "                    inputs_3d = torch.from_numpy(batch.astype('float32'))\n",
    "                    inputs_2d = torch.from_numpy(batch_2d.astype('float32'))\n",
    "                    if torch.cuda.is_available():\n",
    "                        inputs_3d = inputs_3d.cuda()\n",
    "                        inputs_2d = inputs_2d.cuda()\n",
    "                    inputs_traj = inputs_3d[:, :, :1].clone()\n",
    "                    inputs_3d[:, :, 0] = 0\n",
    "\n",
    "                    # Predict 3D poses\n",
    "                    predicted_3d_pos = model_pos(inputs_2d)\n",
    "                    loss_3d_pos = mpjpe(predicted_3d_pos, inputs_3d)\n",
    "                    epoch_loss_3d_valid += inputs_3d.shape[0]*inputs_3d.shape[1] * loss_3d_pos.item()\n",
    "                    N += inputs_3d.shape[0]*inputs_3d.shape[1]\n",
    "                losses_3d_valid.append(epoch_loss_3d_valid / N)\n",
    "                \n",
    "                # Evaluate on training set, this time in evaluation mode\n",
    "                epoch_loss_3d_train_eval = 0\n",
    "                epoch_loss_traj_train_eval = 0\n",
    "                epoch_loss_2d_train_labeled_eval = 0\n",
    "                N = 0\n",
    "                for cam, batch, batch_2d in train_generator_eval.next_epoch():\n",
    "                    if batch_2d.shape[1] == 0:\n",
    "                        # This can only happen when downsampling the dataset\n",
    "                        continue\n",
    "                    inputs_3d = torch.from_numpy(batch.astype('float32'))\n",
    "                    inputs_2d = torch.from_numpy(batch_2d.astype('float32'))\n",
    "                    if torch.cuda.is_available():\n",
    "                        inputs_3d = inputs_3d.cuda()\n",
    "                        inputs_2d = inputs_2d.cuda()\n",
    "                    inputs_traj = inputs_3d[:, :, :1].clone()\n",
    "                    inputs_3d[:, :, 0] = 0\n",
    "                    \n",
    "                    # Compute 3D poses\n",
    "                    predicted_3d_pos = model_pos(inputs_2d)\n",
    "                    loss_3d_pos = mpjpe(predicted_3d_pos, inputs_3d)\n",
    "                    epoch_loss_3d_train_eval += inputs_3d.shape[0]*inputs_3d.shape[1] * loss_3d_pos.item()\n",
    "                    N += inputs_3d.shape[0]*inputs_3d.shape[1]\n",
    "                losses_3d_train_eval.append(epoch_loss_3d_train_eval / N)\n",
    "                \n",
    "                epoch_loss_2d_train_unlabeled_eval = 0\n",
    "                N_semi = 0\n",
    "        elapsed = (time() - start_time)/60\n",
    "        \n",
    "        if args.no_eval:\n",
    "            print('[%d] time %.2f lr %f 3d_train %f' % (\n",
    "                    epoch + 1,\n",
    "                    elapsed,\n",
    "                    lr,\n",
    "                    losses_3d_train[-1] * 1000))\n",
    "        else:\n",
    "            print('[%d] time %.2f lr %f 3d_train %f 3d_eval %f 3d_valid %f' % (\n",
    "                        epoch + 1,\n",
    "                        elapsed,\n",
    "                        lr,\n",
    "                        losses_3d_train[-1] * 1000,\n",
    "                        losses_3d_train_eval[-1] * 1000,\n",
    "                        losses_3d_valid[-1]  *1000))\n",
    "        # Decay learning rate exponentially\n",
    "        lr *= lr_decay\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= lr_decay\n",
    "        epoch += 1\n",
    "        \n",
    "        # Decay BatchNorm momentum\n",
    "        momentum = initial_momentum * np.exp(-epoch/args.epochs * np.log(initial_momentum/final_momentum))\n",
    "        model_pos_train.set_bn_momentum(momentum)\n",
    "        \n",
    "        # Save checkpoint if necessary\n",
    "        if epoch % args.checkpoint_frequency == 0:\n",
    "            chk_path = os.path.join(args.checkpoint, 'epoch_{}.pth'.format(epoch))\n",
    "            print('Saving checkpoint to', chk_path)\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'lr': lr,\n",
    "                'random_state': train_generator.random_state(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'model_pos': model_pos_train.state_dict(),\n",
    "                'model_traj': model_traj_train.state_dict() if semi_supervised else None,\n",
    "                'random_state_semi': semi_generator.random_state() if semi_supervised else None,\n",
    "            }, chk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94a27ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_generator, action=None, return_predictions=False, use_trajectory_model=False):\n",
    "    epoch_loss_3d_pos = 0\n",
    "    epoch_loss_3d_pos_procrustes = 0\n",
    "    epoch_loss_3d_pos_scale = 0\n",
    "    epoch_loss_3d_vel = 0\n",
    "    with torch.no_grad():\n",
    "        if not use_trajectory_model:\n",
    "            model_pos.eval()\n",
    "        else:\n",
    "            model_traj.eval()\n",
    "        N = 0\n",
    "        for _, batch, batch_2d in test_generator.next_epoch():\n",
    "            inputs_2d = torch.from_numpy(batch_2d.astype('float32'))\n",
    "            if torch.cuda.is_available():\n",
    "                inputs_2d = inputs_2d.cuda()\n",
    "\n",
    "            # Positional model\n",
    "            if not use_trajectory_model:\n",
    "                predicted_3d_pos = model_pos(inputs_2d)\n",
    "            else:\n",
    "                predicted_3d_pos = model_traj(inputs_2d)\n",
    "\n",
    "            # Test-time augmentation (if enabled)\n",
    "            if test_generator.augment_enabled():\n",
    "                # Undo flipping and take average with non-flipped version\n",
    "                predicted_3d_pos[1, :, :, 0] *= -1\n",
    "                if not use_trajectory_model:\n",
    "                    predicted_3d_pos[1, :, joints_left + joints_right] = predicted_3d_pos[1, :, joints_right + joints_left]\n",
    "                predicted_3d_pos = torch.mean(predicted_3d_pos, dim=0, keepdim=True)\n",
    "                \n",
    "            if return_predictions:\n",
    "                return predicted_3d_pos.squeeze(0).cpu().numpy()\n",
    "                \n",
    "            inputs_3d = torch.from_numpy(batch.astype('float32'))\n",
    "            if torch.cuda.is_available():\n",
    "                inputs_3d = inputs_3d.cuda()\n",
    "            inputs_3d[:, :, 0] = 0    \n",
    "            if test_generator.augment_enabled():\n",
    "                inputs_3d = inputs_3d[:1]\n",
    "\n",
    "            error = mpjpe(predicted_3d_pos, inputs_3d)\n",
    "            epoch_loss_3d_pos_scale += inputs_3d.shape[0]*inputs_3d.shape[1] * n_mpjpe(predicted_3d_pos, inputs_3d).item()\n",
    "\n",
    "            epoch_loss_3d_pos += inputs_3d.shape[0]*inputs_3d.shape[1] * error.item()\n",
    "            N += inputs_3d.shape[0] * inputs_3d.shape[1]\n",
    "            \n",
    "            inputs = inputs_3d.cpu().numpy().reshape(-1, inputs_3d.shape[-2], inputs_3d.shape[-1])\n",
    "            predicted_3d_pos = predicted_3d_pos.cpu().numpy().reshape(-1, inputs_3d.shape[-2], inputs_3d.shape[-1])\n",
    "\n",
    "            epoch_loss_3d_pos_procrustes += inputs_3d.shape[0]*inputs_3d.shape[1] * p_mpjpe(predicted_3d_pos, inputs)\n",
    "\n",
    "            # Compute velocity error\n",
    "            epoch_loss_3d_vel += inputs_3d.shape[0]*inputs_3d.shape[1] * mean_velocity_error(predicted_3d_pos, inputs)\n",
    "            \n",
    "    if action is None:\n",
    "        print('----------')\n",
    "    else:\n",
    "        print('----'+action+'----')\n",
    "    e1 = (epoch_loss_3d_pos / N)*1000\n",
    "    e2 = (epoch_loss_3d_pos_procrustes / N)*1000\n",
    "    e3 = (epoch_loss_3d_pos_scale / N)*1000\n",
    "    ev = (epoch_loss_3d_vel / N)*1000\n",
    "    print('Test time augmentation:', test_generator.augment_enabled())\n",
    "    print('Protocol #1 Error (MPJPE):', e1, 'mm')\n",
    "    print('Protocol #2 Error (P-MPJPE):', e2, 'mm')\n",
    "    print('Protocol #3 Error (N-MPJPE):', e3, 'mm')\n",
    "    print('Velocity Error (MPJVE):', ev, 'mm')\n",
    "    print('----------')\n",
    "\n",
    "    return e1, e2, e3, ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af5766a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TemporalModel(\n",
      "  (drop): Dropout(p=0.25, inplace=False)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (expand_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (shrink): Conv1d(1024, 51, kernel_size=(1,), stride=(1,))\n",
      "  (expand_conv): Conv1d(34, 1024, kernel_size=(3,), stride=(1,), bias=False)\n",
      "  (layers_conv): ModuleList(\n",
      "    (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), dilation=(3,), bias=False)\n",
      "    (1): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (2): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), dilation=(9,), bias=False)\n",
      "    (3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (4): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), dilation=(27,), bias=False)\n",
      "    (5): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (6): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), dilation=(81,), bias=False)\n",
      "    (7): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (layers_bn): ModuleList(\n",
      "    (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1            [-1, 1024, 241]         104,448\n",
      "       BatchNorm1d-2            [-1, 1024, 241]           2,048\n",
      "              ReLU-3            [-1, 1024, 241]               0\n",
      "           Dropout-4            [-1, 1024, 241]               0\n",
      "            Conv1d-5            [-1, 1024, 235]       3,145,728\n",
      "       BatchNorm1d-6            [-1, 1024, 235]           2,048\n",
      "              ReLU-7            [-1, 1024, 235]               0\n",
      "           Dropout-8            [-1, 1024, 235]               0\n",
      "            Conv1d-9            [-1, 1024, 235]       1,048,576\n",
      "      BatchNorm1d-10            [-1, 1024, 235]           2,048\n",
      "             ReLU-11            [-1, 1024, 235]               0\n",
      "          Dropout-12            [-1, 1024, 235]               0\n",
      "           Conv1d-13            [-1, 1024, 217]       3,145,728\n",
      "      BatchNorm1d-14            [-1, 1024, 217]           2,048\n",
      "             ReLU-15            [-1, 1024, 217]               0\n",
      "          Dropout-16            [-1, 1024, 217]               0\n",
      "           Conv1d-17            [-1, 1024, 217]       1,048,576\n",
      "      BatchNorm1d-18            [-1, 1024, 217]           2,048\n",
      "             ReLU-19            [-1, 1024, 217]               0\n",
      "          Dropout-20            [-1, 1024, 217]               0\n",
      "           Conv1d-21            [-1, 1024, 163]       3,145,728\n",
      "      BatchNorm1d-22            [-1, 1024, 163]           2,048\n",
      "             ReLU-23            [-1, 1024, 163]               0\n",
      "          Dropout-24            [-1, 1024, 163]               0\n",
      "           Conv1d-25            [-1, 1024, 163]       1,048,576\n",
      "      BatchNorm1d-26            [-1, 1024, 163]           2,048\n",
      "             ReLU-27            [-1, 1024, 163]               0\n",
      "          Dropout-28            [-1, 1024, 163]               0\n",
      "           Conv1d-29              [-1, 1024, 1]       3,145,728\n",
      "      BatchNorm1d-30              [-1, 1024, 1]           2,048\n",
      "             ReLU-31              [-1, 1024, 1]               0\n",
      "          Dropout-32              [-1, 1024, 1]               0\n",
      "           Conv1d-33              [-1, 1024, 1]       1,048,576\n",
      "      BatchNorm1d-34              [-1, 1024, 1]           2,048\n",
      "             ReLU-35              [-1, 1024, 1]               0\n",
      "          Dropout-36              [-1, 1024, 1]               0\n",
      "           Conv1d-37                [-1, 51, 1]          52,275\n",
      "================================================================\n",
      "Total params: 16,952,371\n",
      "Trainable params: 16,952,371\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 46.03\n",
      "Params size (MB): 64.67\n",
      "Estimated Total Size (MB): 110.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = TemporalModel(poses_valid_2d[0].shape[-2], poses_valid_2d[0].shape[-1], dataset.skeleton().num_joints(),\n",
    "                            filter_widths=filter_widths, causal=args.causal, dropout=args.dropout, channels=args.channels,\n",
    "                            dense=args.dense)\n",
    "checkpoint_tmp = torch.load(\"/home/gsc/pose_estimation_baseline/2d_to_3d_lifting_baseline/checkpoint243/epoch_80.pth\", map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(checkpoint_tmp['model_pos'])\n",
    "\n",
    "print(model)\n",
    "model.to('cuda')\n",
    "torchsummary.summary(model,input_size = (243,17,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2884406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f07d98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsc/pose_estimation_baseline/2d_to_3d_lifting_baseline/common/model.py:65: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert x.shape[-2] == self.num_joints_in\n",
      "/home/gsc/pose_estimation_baseline/2d_to_3d_lifting_baseline/common/model.py:66: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert x.shape[-1] == self.in_features\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1,243,17,2,requires_grad=True).cuda()\n",
    "dummy_input.is_cuda\n",
    "model(dummy_input)\n",
    "torch.onnx.export(model,\n",
    "                 dummy_input,\n",
    "                 \"videopose243.onnx\",\n",
    "                 verbose=False,\n",
    "                 input_names=['input'],\n",
    "                 output_names=['output'],\n",
    "                 export_params=True,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9891cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#                 'epoch': epoch,\n",
    "#                 'lr': lr,\n",
    "#                 'random_state': train_generator.random_state(),\n",
    "#                 'optimizer': optimizer.state_dict(),\n",
    "#                 'model_pos': model_pos_train.state_dict(),\n",
    "#                 'model_traj': model_traj_train.state_dict() if semi_supervised else None,\n",
    "#                 'random_state_semi': semi_generator.random_state() if semi_supervised else None,\n",
    "#             }, chk_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
