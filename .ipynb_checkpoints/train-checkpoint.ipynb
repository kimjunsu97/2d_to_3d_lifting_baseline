{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79fdd771-aada-4898-901e-b733c833134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#from common.arguments import parse_args\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import sys\n",
    "import errno\n",
    "\n",
    "from common.camera import *\n",
    "# from common.model import *\n",
    "# from common.loss import *\n",
    "from common.generators import ChunkedGenerator, UnchunkedGenerator\n",
    "from time import time\n",
    "from common.utils import deterministic_random\n",
    "\n",
    "from common.h36m_dataset import Human36mDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f05fe11b-e8a3-44e4-ae1f-fd7041ff2478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h36m\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    dataset = 'h36m'\n",
    "    keypoints = 'gt'\n",
    "    subjects_train = ['S1','S5','S6','S7','S8']\n",
    "    subjects_test = ['S9','S11']\n",
    "    subjects_unlabeled = ''\n",
    "    actions = '*'\n",
    "    checkpoint = None\n",
    "    render = False\n",
    "    \n",
    "    #Model\n",
    "    stride = 1\n",
    "    epochs = 60\n",
    "    batch_size = 1024\n",
    "    dropout = 0.25\n",
    "    learning_rate = 0.001\n",
    "    lr_decay = 0.95\n",
    "    architecture = '3,3,3'\n",
    "    causal = True\n",
    "    \n",
    "    #Experimental\n",
    "    subset = 1\n",
    "    downsample = 1\n",
    "    warmup = 1\n",
    "    \n",
    "args = Args()\n",
    "print(args.dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "255a56b8-d610-43f7-bc7d-c6930146c592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data_3d_h36m.npz\n"
     ]
    }
   ],
   "source": [
    "dataset_path = dataset_path = 'data/data_3d_' + args.dataset + '.npz'\n",
    "print(dataset_path)\n",
    "dataset = Human36mDataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26fd6c69-dfc4-449a-8108-90f9e333f615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing 3d data...\n"
     ]
    }
   ],
   "source": [
    "print('Preparing 3d data...')\n",
    "for subject in dataset.subjects():\n",
    "    for action in dataset[subject].keys():\n",
    "        anim = dataset[subject][action]\n",
    "        \n",
    "        if 'positions' in anim:\n",
    "            positions_3d = []\n",
    "            for cam in anim['cameras']:\n",
    "                pos_3d = world_to_camera(anim['positions'], R=cam['orientation'], t=cam['translation'])\n",
    "                pos_3d[:, 1:] -= pos_3d[:, :1] # Remove global offset, but keep trajectory in first position\n",
    "                positions_3d.append(pos_3d)\n",
    "            anim['positions_3d'] = positions_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "748a384f-4621-4de3-8e4a-7265c100efeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2D detections...\n"
     ]
    }
   ],
   "source": [
    "print('Loading 2D detections...')\n",
    "keypoints = np.load('data/data_2d_' + args.dataset + '_' + args.keypoints + '.npz', allow_pickle=True)\n",
    "keypoints_metadata = keypoints['metadata'].item()\n",
    "keypoints_symmetry = keypoints_metadata['keypoints_symmetry']\n",
    "kps_left, kps_right = list(keypoints_symmetry[0]), list(keypoints_symmetry[1])\n",
    "joints_left, joints_right = list(dataset.skeleton().joints_left()), list(dataset.skeleton().joints_right())\n",
    "keypoints = keypoints['positions_2d'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472e1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in dataset.subjects():\n",
    "    assert subject in keypoints, 'Subject {} is missing from the 2D detections dataset'.format(subject)\n",
    "    for action in dataset[subject].keys():\n",
    "        assert action in keypoints[subject], 'Action {} of subject {} is missing from the 2D detections dataset'.format(action, subject)\n",
    "        if 'positions_3d' not in dataset[subject][action]:\n",
    "            continue\n",
    "            \n",
    "        for cam_idx in range(len(keypoints[subject][action])):\n",
    "            \n",
    "            # We check for >= instead of == because some videos in H3.6M contain extra frames\n",
    "            mocap_length = dataset[subject][action]['positions_3d'][cam_idx].shape[0]\n",
    "            assert keypoints[subject][action][cam_idx].shape[0] >= mocap_length\n",
    "            \n",
    "            if keypoints[subject][action][cam_idx].shape[0] > mocap_length:\n",
    "                # Shorten sequence\n",
    "                keypoints[subject][action][cam_idx] = keypoints[subject][action][cam_idx][:mocap_length]\n",
    "\n",
    "        assert len(keypoints[subject][action]) == len(dataset[subject][action]['positions_3d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d990389",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in keypoints.keys():\n",
    "    for action in keypoints[subject]:\n",
    "        for cam_idx, kps in enumerate(keypoints[subject][action]):\n",
    "            # Normalize camera frame\n",
    "            cam = dataset.cameras()[subject][cam_idx]\n",
    "            kps[..., :2] = normalize_screen_coordinates(kps[..., :2], w=cam['res_w'], h=cam['res_h'])\n",
    "            keypoints[subject][action][cam_idx] = kps\n",
    "subjects_train = args.subjects_train\n",
    "subjects_semi = [] if not args.subjects_unlabeled else args.subjects_unlabeled.split(',')\n",
    "if not args.render:\n",
    "    subjects_test = args.subjects_test\n",
    "else:\n",
    "    subjects_test = [args.viz_subject]\n",
    "\n",
    "semi_supervised = len(subjects_semi) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b29a0b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(subjects, action_filter=None, subset=1, parse_3d_poses=True):\n",
    "    out_poses_3d = []\n",
    "    out_poses_2d = []\n",
    "    out_camera_params = []\n",
    "    for subject in subjects:\n",
    "        for action in keypoints[subject].keys():\n",
    "            ############################\n",
    "            if action_filter is not None:\n",
    "                found = False\n",
    "                for a in action_filter:\n",
    "                    if action.startswith(a):\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    continue\n",
    "            ############################    \n",
    "            poses_2d = keypoints[subject][action]\n",
    "            for i in range(len(poses_2d)): # Iterate across cameras\n",
    "                out_poses_2d.append(poses_2d[i])\n",
    "            # 카메라 4방향 이어주기\n",
    "            \n",
    "            if subject in dataset.cameras():\n",
    "                cams = dataset.cameras()[subject]\n",
    "                assert len(cams) == len(poses_2d), 'Camera count mismatch'\n",
    "                for cam in cams:\n",
    "                    if 'intrinsic' in cam:\n",
    "                        out_camera_params.append(cam['intrinsic'])\n",
    "            # 카메라 내부 파라미터\n",
    "            \n",
    "            if parse_3d_poses and 'positions_3d' in dataset[subject][action]:\n",
    "                poses_3d = dataset[subject][action]['positions_3d']\n",
    "                assert len(poses_3d) == len(poses_2d), 'Camera count mismatch'\n",
    "                for i in range(len(poses_3d)): # Iterate across cameras\n",
    "                    out_poses_3d.append(poses_3d[i])\n",
    "    \n",
    "    if len(out_camera_params) == 0:\n",
    "        out_camera_params = None\n",
    "    if len(out_poses_3d) == 0:\n",
    "        out_poses_3d = None\n",
    "    \n",
    "    stride = args.downsample\n",
    "    if subset < 1:\n",
    "        for i in range(len(out_poses_2d)):\n",
    "            n_frames = int(round(len(out_poses_2d[i])//stride * subset)*stride)\n",
    "            start = deterministic_random(0, len(out_poses_2d[i]) - n_frames + 1, str(len(out_poses_2d[i])))\n",
    "            out_poses_2d[i] = out_poses_2d[i][start:start+n_frames:stride]\n",
    "            if out_poses_3d is not None:\n",
    "                out_poses_3d[i] = out_poses_3d[i][start:start+n_frames:stride]\n",
    "    elif stride > 1:\n",
    "        # Downsample as requested\n",
    "        for i in range(len(out_poses_2d)):\n",
    "            out_poses_2d[i] = out_poses_2d[i][::stride]\n",
    "            if out_poses_3d is not None:\n",
    "                out_poses_3d[i] = out_poses_3d[i][::stride]\n",
    "    \n",
    "\n",
    "    return out_camera_params, out_poses_3d, out_poses_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42ac5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_filter = None if args.actions == '*' else args.actions.split(',')\n",
    "if action_filter is not None:\n",
    "    print('Selected actions:', action_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b0c4595",
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras_valid, poses_valid, poses_valid_2d = fetch(subjects_test, action_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d592490",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Args' object has no attribute 'architecture'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14627/2397753020.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilter_widths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Args' object has no attribute 'architecture'"
     ]
    }
   ],
   "source": [
    "filter_widths = [int(x) for x in args.architecture.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233fa4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
